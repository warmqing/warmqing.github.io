<!DOCTYPE html><html><head><meta name="generator" content="Hexo 3.8.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="Spark——Structured streaming + hive sink"><meta name="keywords" content="scala,spark"><meta name="author" content="warmqing"><meta name="copyright" content="warmqing"><meta name="google-site-verification" content="r6fMmphB-u3s7p5myuSngUw4xAgHUz0nII5QYBUBG6c"><meta name="baidu-site-verification" content="5cSbHnUUCL"><title>Spark——Structured streaming + hive sink | Oolong Box</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.6.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.6.1"><link rel="dns-prefetch" href="https://cdn.staticfile.org"><link rel="dns-prefetch" href="https://cdn.bootcss.com"><link rel="dns-prefetch" href="https://creativecommons.org"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.1.1/dist/instantsearch.min.css"><script src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.1.1/dist/instantsearch.min.js" defer></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js"></script><script src="https://cdn.jsdelivr.net/npm/blueimp-md5@2.10.0/js/md5.min.js"></script><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script>(adsbygoogle = window.adsbygoogle || []).push({
  google_ad_client: 'ca-pub-4146880878125243',
  enable_page_level_ads: 'true'
});
</script><link rel="dns-prefetch" href="https://hm.baidu.com"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?a30a198fc71d7b0aa216b4f7f31698a2";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();</script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: {"appId":"V8UUR9G3TF","apiKey":"5a765edf66f2abc7c0a86abdac87b2de","indexName":"blog_index","hits":{"per_page":10},"languages":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}.","hits_stats":"${hits} results found in ${time} ms"}},
  localSearch: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  }
} </script></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar"><div class="toggle-sidebar-info text-center"><span data-toggle="Toggle article">Toggle site</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Spark——Structured-streaming-hive-sink"><span class="toc-number">1.</span> <span class="toc-text">Spark——Structured streaming + hive sink</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#背景"><span class="toc-number">1.1.</span> <span class="toc-text">背景</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Structured-streaming-消费kafka"><span class="toc-number">1.2.</span> <span class="toc-text">Structured streaming 消费kafka</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#消费kafka数据，对json数据进行transform"><span class="toc-number">1.2.1.</span> <span class="toc-text">消费kafka数据，对json数据进行transform</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#自定义Sink"><span class="toc-number">1.3.</span> <span class="toc-text">自定义Sink</span></a></li></ol></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/img/avatar.png"></div><div class="author-info__name text-center">warmqing</div><div class="author-info__description text-center"></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">8</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">5</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">2</span></a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://i.loli.net/2019/04/04/5ca58c8caa281.jpg)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">Oolong Box</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus"><a class="site-page social-icon search"><i class="fa fa-search"></i><span> Search</span></a><a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span></div><div id="post-info"><div id="post-title">Spark——Structured streaming + hive sink</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2019-09-18</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/日志/">日志</a></div></div></div><div class="layout layout_post" id="content-inner"><article id="post"><div class="article-container" id="post-content"><h1 id="Spark——Structured-streaming-hive-sink"><a href="#Spark——Structured-streaming-hive-sink" class="headerlink" title="Spark——Structured streaming + hive sink"></a>Spark——Structured streaming + hive sink</h1><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>需求：Structured streaming消费kafka并将数据写入Hive表</p>
<p>spark 版本 2.3.1</p>
<p>scala 版本 2.11.8</p>
<p>spark从2.4版本以后，支持foreachBatch</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">streamingDF.writeStream.foreachBatch &#123; (batchDF: <span class="type">DataFrame</span>, batchId: <span class="type">Long</span>) =&gt;</span><br><span class="line">  <span class="comment">// Transform and write batchDF </span></span><br><span class="line">&#125;.start()</span><br></pre></td></tr></table></figure>
<p>所以本次需要自定义sink实现写Hive的操作</p>
<h2 id="Structured-streaming-消费kafka"><a href="#Structured-streaming-消费kafka" class="headerlink" title="Structured streaming 消费kafka"></a>Structured streaming 消费kafka</h2><h3 id="消费kafka数据，对json数据进行transform"><a href="#消费kafka数据，对json数据进行transform" class="headerlink" title="消费kafka数据，对json数据进行transform"></a>消费kafka数据，对json数据进行transform</h3><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.sql.<span class="type">Timestamp</span></span><br><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.&#123;<span class="type">JSON</span>, <span class="type">JSONObject</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">SparkSession</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.streaming.<span class="type">Trigger</span></span><br><span class="line"><span class="keyword">import</span> org.slf4j.<span class="type">LoggerFactory</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">StructuredReceiver</span> </span>&#123;</span><br><span class="line">  <span class="keyword">val</span> <span class="type">LOGGER</span> = <span class="type">LoggerFactory</span>.getLogger(<span class="type">StructuredReceiver</span>.getClass)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">var</span> suffix = <span class="string">""</span></span><br><span class="line">    <span class="keyword">if</span> (args != <span class="literal">null</span> &amp;&amp; args.length &gt;= <span class="number">1</span>) &#123;</span><br><span class="line">      suffix = args(<span class="number">0</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> checkpointDirectory = <span class="string">"/user/checkpoint/StructuredReceiver"</span> + suffix</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"StructuredReceiver"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> ss = <span class="type">SparkSession</span>.builder().enableHiveSupport().config(conf).getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">import</span> ss.implicits._</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> lines = ss</span><br><span class="line">      .readStream</span><br><span class="line">      .format(<span class="string">"kafka"</span>)</span><br><span class="line">      .option(<span class="string">"kafka.bootstrap.servers"</span>, <span class="string">"host1:port1,host2:port2"</span>)</span><br><span class="line">      .option(<span class="string">"subscribe"</span>, <span class="string">"topic"</span>)</span><br><span class="line">      .load()</span><br><span class="line">      .selectExpr(<span class="string">"CAST(key AS STRING)"</span>, <span class="string">"CAST(value AS STRING)"</span>, <span class="string">"CAST(timestamp AS TIMESTAMP)"</span>)</span><br><span class="line">      .as[(<span class="type">String</span>, <span class="type">String</span>, <span class="type">Timestamp</span>)]</span><br><span class="line"></span><br><span class="line">	<span class="comment">//数据transform</span></span><br><span class="line">    <span class="keyword">val</span> resultDf = lines.map(record =&gt; &#123;</span><br><span class="line">      <span class="keyword">var</span> json: <span class="type">JSONObject</span> = <span class="literal">null</span></span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        json = <span class="type">JSON</span>.parseObject(record._2)</span><br><span class="line">      &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> e: <span class="type">Exception</span> =&gt; &#123;</span><br><span class="line">          <span class="type">LOGGER</span>.warn(<span class="string">"parse josn erro"</span>, e)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (json == <span class="literal">null</span> || json.isEmpty) &#123;</span><br><span class="line">        (<span class="literal">null</span>, <span class="literal">null</span>)</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">val</span> appName = json.getString(<span class="string">"appName"</span>)</span><br><span class="line">        <span class="keyword">val</span> msg = json.getString(<span class="string">"msg"</span>)</span><br><span class="line">        (appName, msg)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;).filter(pair =&gt; pair._1 != <span class="literal">null</span> &amp;&amp; pair._1 != <span class="string">""</span> &amp;&amp; pair._2 != <span class="literal">null</span> &amp;&amp; pair._2 != <span class="string">""</span>).map(pair =&gt; &#123;</span><br><span class="line">      <span class="keyword">val</span> appName = pair._1</span><br><span class="line">      <span class="keyword">val</span> msg = pair._2</span><br><span class="line">      <span class="keyword">val</span> values = msg.split(<span class="string">"\t"</span>)</span><br><span class="line">      (values(<span class="number">0</span>), values(<span class="number">1</span>).toLong, values(<span class="number">2</span>).toInt, values(<span class="number">3</span>))</span><br><span class="line">    &#125;).toDF()</span><br><span class="line"></span><br><span class="line">    resultDf.writeStream</span><br><span class="line">      .outputMode(<span class="string">"append"</span>)</span><br><span class="line">      .trigger(<span class="type">Trigger</span>.<span class="type">ProcessingTime</span>(<span class="string">"10 seconds"</span>))<span class="comment">//批次时间</span></span><br><span class="line">      .format(<span class="string">"com.warmqing.spark.HiveSinkProvider"</span>)<span class="comment">//自定义HiveSinkProvider</span></span><br><span class="line">      .option(<span class="string">"checkpointLocation"</span>, checkpointDirectory)</span><br><span class="line">      .start()</span><br><span class="line">      .awaitTermination()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="自定义Sink"><a href="#自定义Sink" class="headerlink" title="自定义Sink"></a>自定义Sink</h2><p>定义sink，将结构化数据写入Hive分区表</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.text.<span class="type">SimpleDateFormat</span></span><br><span class="line"><span class="keyword">import</span> java.util.<span class="type">Date</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.catalyst.<span class="type">CatalystTypeConverters</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.execution.streaming.<span class="type">Sink</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions.lit</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.sources.&#123;<span class="type">DataSourceRegister</span>, <span class="type">StreamSinkProvider</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.streaming.<span class="type">OutputMode</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.types._</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.&#123;<span class="type">DataFrame</span>, <span class="type">Row</span>, <span class="type">SQLContext</span>, <span class="type">SaveMode</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.<span class="type">LoggerFactory</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">HiveSink</span>(<span class="params">sqlContext: <span class="type">SQLContext</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                              parameters: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>],</span></span></span><br><span class="line"><span class="class"><span class="params">                              partitionColumns: <span class="type">Seq</span>[<span class="type">String</span>],</span></span></span><br><span class="line"><span class="class"><span class="params">                              outputMode: <span class="type">OutputMode</span></span>) <span class="keyword">extends</span> <span class="title">Sink</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">addBatch</span></span>(batchId: <span class="type">Long</span>, data: <span class="type">DataFrame</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> logger = <span class="type">LoggerFactory</span>.getLogger(<span class="keyword">this</span>.getClass)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> schema = <span class="type">StructType</span>(<span class="type">Array</span>(</span><br><span class="line">      <span class="type">StructField</span>(<span class="string">"app_name"</span>, <span class="type">StringType</span>),</span><br><span class="line">      <span class="type">StructField</span>(<span class="string">"event_time"</span>, <span class="type">LongType</span>),</span><br><span class="line">      <span class="type">StructField</span>(<span class="string">"type"</span>, <span class="type">IntegerType</span>),</span><br><span class="line">      <span class="type">StructField</span>(<span class="string">"uuid"</span>, <span class="type">StringType</span>)</span><br><span class="line">    ))</span><br><span class="line">    <span class="keyword">val</span> res = data.queryExecution.toRdd.mapPartitions &#123; rows =&gt;</span><br><span class="line">      <span class="keyword">val</span> converter = <span class="type">CatalystTypeConverters</span>.createToScalaConverter(schema)</span><br><span class="line">      rows.map(converter(_).asInstanceOf[<span class="type">Row</span>])</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 转化df格式</span></span><br><span class="line">    <span class="keyword">var</span> df = data.sparkSession.createDataFrame(res, schema)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> dateFormat: <span class="type">SimpleDateFormat</span> = <span class="keyword">new</span> <span class="type">SimpleDateFormat</span>(<span class="string">"yyyy-MM-dd"</span>)</span><br><span class="line">    <span class="keyword">val</span> date = dateFormat.format(<span class="keyword">new</span> <span class="type">Date</span>())</span><br><span class="line"></span><br><span class="line">    df = df.withColumn(<span class="string">"dt"</span>, lit(date))</span><br><span class="line">    df.write.mode(<span class="type">SaveMode</span>.<span class="type">Append</span>).format(<span class="string">"hive"</span>).partitionBy(<span class="string">"dt"</span>).saveAsTable(<span class="string">"Hive_table"</span>)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HiveSinkProvider</span> <span class="keyword">extends</span> <span class="title">StreamSinkProvider</span> <span class="keyword">with</span> <span class="title">DataSourceRegister</span> </span>&#123;</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">createSink</span></span>(sqlContext: <span class="type">SQLContext</span>, parameters: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>], partitionColumns: <span class="type">Seq</span>[<span class="type">String</span>], outputMode: <span class="type">OutputMode</span>): <span class="type">Sink</span> = &#123;</span><br><span class="line">    <span class="type">HiveSink</span>(sqlContext, parameters, partitionColumns, outputMode)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">shortName</span></span>(): <span class="type">String</span> = <span class="string">"HiveSinkProvider"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">warmqing</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://www.oolongbox.com/box/2c3ea3f5/">https://www.oolongbox.com/box/2c3ea3f5/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/scala/">scala</a><a class="post-meta__tags" href="/tags/spark/">spark</a></div><div class="social-share pull-right" data-disabled="google,facebook,twitter,diandian"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script><nav id="pagination"><div class="prev-post pull-left"><a href="/box/0/"><i class="fa fa-chevron-left">  </i><span></span></a></div><div class="next-post pull-right"><a href="/box/8be2bca3/"><span>Elasticsearch 深分页问题</span><i class="fa fa-chevron-right"></i></a></div></nav><div id="gitalk-container"></div><script>var gitalk = new Gitalk({
  clientID: 'e343eec37961426a217b',
  clientSecret: '0dff9aff9e10fee7e342bf5e41f15cd9bf02c9b4',
  repo: 'warmqing.github.io',
  owner: 'warmqing',
  admin: 'warmqing',
  id: md5(decodeURI(location.pathname)),
  language: ''
})
gitalk.render('gitalk-container')</script></div></div><footer class="footer-bg" style="background-image: url(https://i.loli.net/2019/04/04/5ca58c8caa281.jpg)"><div class="layout" id="footer"><div class="copyright">&copy;2013 - 2019 By warmqing</div><div class="framework-info"><span>Driven - </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file-o"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.6.1"></script><script src="/js/fancybox.js?version=1.6.1"></script><script src="/js/sidebar.js?version=1.6.1"></script><script src="/js/copy.js?version=1.6.1"></script><script src="/js/fireworks.js?version=1.6.1"></script><script src="/js/transition.js?version=1.6.1"></script><script src="/js/scroll.js?version=1.6.1"></script><script src="/js/head.js?version=1.6.1"></script><script src="/js/search/algolia.js"></script><script id="ribbon" src="/js/canvas-ribbon.js" size="150" alpha="0.6" zindex="-1"></script><script>if(/Android|webOS|iPhone|iPod|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
}</script><div class="search-dialog" id="algolia-search"><div class="search-dialog__title" id="algolia-search-title">Algolia</div><div id="algolia-input-panel"><div id="algolia-search-input"></div></div><hr><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-stats"></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>